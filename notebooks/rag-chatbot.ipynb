{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f6d6fe-b7f0-4e52-88bf-6aaf84d4674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import set_seed, generate_namespace\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97740a42-b9fd-43de-907b-9e503ec9f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_name\": \"gpt2\",\n",
      "  \"api_model_name\": \"gpt-4.1-nano\",\n",
      "  \"seed\": 42,\n",
      "  \"n_turns\": 6,\n",
      "  \"log_dir\": \"../outputs/logs/\",\n",
      "  \"state_dir\": \"../outputs/state/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cfg = generate_namespace(path=f\"../config.yaml\")\n",
    "print(json.dumps(vars(cfg), indent=2))\n",
    "\n",
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42de90f9-5d5f-45f8-9c34-7438045ee0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "\n",
      "Use ONLY the information below to answer.\n",
      "Context:\n",
      "Transformers rely on self-attention mechanisms to model token relationships.\n",
      "\n",
      "Question: How do transformers work?\n",
      "Answer: The idea of \"transform\" is an oxymoron, but one that can easily be translated into many ways and used in several different contexts. One way involves using tokens as their own unique entities or objects (i) rather than just being part people's identity categories for each other; ii), by creating new roles with additional identities at birth via inheritance from parents/infants who share certain traits within themselves (\"tribal\", etc.), i.) through use among children such aspects thereof like gender alignment\n"
     ]
    }
   ],
   "source": [
    "from rag_chatbot.documents import DOCUMENTS\n",
    "from rag_chatbot.retriever import DocsRetriever\n",
    "from rag_chatbot.rag_prompt import build_rag_prompt\n",
    "from basic_chatbot.model_local import LocalLM\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "retriever = DocsRetriever(DOCUMENTS)\n",
    "lm = LocalLM(cfg.model_name)\n",
    "user_question = \"How do transformers work?\"\n",
    "\n",
    "docs = retriever.retrieve(user_question, k=1)\n",
    "prompt = build_rag_prompt(\n",
    "    system_prompt,\n",
    "    docs,\n",
    "    user_question\n",
    ")\n",
    "\n",
    "print(lm.generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af591cb5-4345-4bf8-ae9f-3cb82a5e4341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
